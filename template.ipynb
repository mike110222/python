{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "dspath=\"./datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def dummyf(x):\n",
    "\treturn x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "for i in range(decoded.shape[0]):\n",
    "\n",
    "    array=decoded[i,0,:,:,0]\n",
    "    \n",
    "    # Plot the array as a grayscale image\n",
    "    plt.imshow(array, cmap='gray')\n",
    "\n",
    "    plt.colorbar()  # Add a color bar to the side for reference\n",
    "    plt.title('Grayscale Image of 128x128 Array')\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(10, 6, figsize=(12, 15))\n",
    "for i in range(10):\n",
    "\tfor j in range(6):\n",
    "\t\tarray=decoded[6*i+j,0,:,:,0]\n",
    "\t\taxes[i, j].imshow(array, cmap='gray')\n",
    "\t\taxes[i, j].set_title(f\"Plot {6*i+j+1}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# jax checkpoints\n",
    "import jax.numpy as jnp\n",
    "from flax.training import checkpoints\n",
    "import os\n",
    "ckpt_dir = os.getcwd()+\"/checkpoints/TEST\"\n",
    "\n",
    "restored={}\n",
    "state = {'a':jnp.ones(16)}\n",
    "#restored = checkpoints.restore_checkpoint(ckpt_dir, state, prefix=f\"_ARRAY_\")\n",
    "\n",
    "checkpoints.save_checkpoint(ckpt_dir, state, 1, prefix=f\"_ARRAY_\", keep=5, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic TrainState\n",
    "import flax.linen as nn\n",
    "from flax.training.train_state import TrainState\n",
    "import jax, jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "x = jnp.ones((1,2))\n",
    "y = jnp.ones((1,2))\n",
    "z = jnp.array([[1,1],[-2,4],[0,3]])\n",
    "model = nn.Dense(2)\n",
    "variables = model.init(jax.random.key(0), x)\n",
    "tx = optax.adam(2e-2)\n",
    "\n",
    "state=TrainState.create(apply_fn=model.apply, params=variables, tx=tx)\n",
    "\n",
    "#print(state.params['params']['kernel'])\n",
    "#print(model.apply(state.params,z))\n",
    "\n",
    "def loss(params, x, y):\n",
    "\tpredictions=state.apply_fn(params,x)\n",
    "\treturn optax.l2_loss(predictions,y).mean()\n",
    "print(loss(state.params,x,y))\n",
    "\n",
    "for _ in range(300):\n",
    "\t\n",
    "\tgrads=jax.grad(loss)(state.params,x,y)\n",
    "\tstate=state.apply_gradients(grads=grads)\n",
    "\t#display(loss(state.params,x,y))\n",
    "\n",
    "print(state.params)\n",
    "print(loss(state.params,x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers pipeline\n",
    "# long loading time\n",
    "from transformers import pipeline\n",
    "\n",
    "'''# Test a pre-trained pipeline (e.g., sentiment-analysis)\n",
    "classifier = pipeline(task='sentiment-analysis',device='cuda')\n",
    "print(classifier(\"Hello World\"))\n",
    "print(classifier([\"Hugging Face is amazing!\",\"Red Blue yellow\"]))\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\", device='cuda')\n",
    "print(generator(\"Once upon a time\", max_length=50, num_return_sequences=1))\n",
    "print(generator(\"I've always been shy growing up.\", max_length=250, num_return_sequences=1))'''\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokens1 = tokenizer(\"Hello, how are you?\", return_tensors=\"pt\")\n",
    "tokens2 = tokenizer(\"Hello\", return_tensors=\"pt\")\n",
    "print(tokens1)\n",
    "print(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mode Output: tensor([[-1.2247, -1.2247, -1.2247],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 1.2247,  1.2247,  1.2247]], grad_fn=<NativeBatchNormBackward0>)\n",
      "OrderedDict([('weight', tensor([1., 1., 1.])), ('bias', tensor([0., 0., 0.])), ('running_mean', tensor([0.4000, 0.5000, 0.6000])), ('running_var', tensor([1.8000, 1.8000, 1.8000])), ('num_batches_tracked', tensor(1))])\n",
      "Evaluation Mode Output: tensor([[2.6833, 0.3727, 4.0249],\n",
      "        [4.9193, 5.5902, 6.2610]], grad_fn=<NativeBatchNormBackward0>)\n",
      "OrderedDict([('weight', tensor([1., 1., 1.])), ('bias', tensor([0., 0., 0.])), ('running_mean', tensor([0.4000, 0.5000, 0.6000])), ('running_var', tensor([1.8000, 1.8000, 1.8000])), ('num_batches_tracked', tensor(1))])\n",
      "Evaluation Mode Output: tensor([[4.9193, 5.5902, 6.2610]], grad_fn=<NativeBatchNormBackward0>)\n",
      "OrderedDict([('weight', tensor([1., 1., 1.])), ('bias', tensor([0., 0., 0.])), ('running_mean', tensor([0.4000, 0.5000, 0.6000])), ('running_var', tensor([1.8000, 1.8000, 1.8000])), ('num_batches_tracked', tensor(1))])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch BatchNorm evaluation mode issue\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Define a BatchNorm layer\n",
    "bn = nn.BatchNorm1d(3,momentum=0.1)\n",
    "\n",
    "# Simulate training mode\n",
    "bn.train()  # Training mode\n",
    "input_train = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n",
    "output_train = bn(input_train)\n",
    "print(\"Training Mode Output:\", output_train)\n",
    "\n",
    "'''mean_rows = np.mean(np.array(input_train), axis=0)\n",
    "\n",
    "# Variance along columns (axis=0)\n",
    "variance_cols = np.var(np.array(input_train), axis=0)\n",
    "\n",
    "print(\"Mean along rows:\", mean_rows)\n",
    "print(\"Variance along columns:\", variance_cols)'''\n",
    "\n",
    "\n",
    "'''print([pn, p] for pn,p in bn.named_parameters())\n",
    "for pn,p in bn.named_parameters():\n",
    "\tprint([pn,p])'''\n",
    "print(bn.state_dict())\n",
    "\n",
    "# Switch to evaluation mode\n",
    "bn.eval()  # Evaluation mode\n",
    "input_eval = torch.tensor([[4.0, 1.0, 6.0],[7.0, 8.0, 9.0]])\n",
    "output_eval = bn(input_eval)\n",
    "print(\"Evaluation Mode Output:\", output_eval)\n",
    "print(bn.state_dict())\n",
    "\n",
    "input_eval = torch.tensor([[7.0, 8.0, 9.0]])\n",
    "output_eval = bn(input_eval)\n",
    "print(\"Evaluation Mode Output:\", output_eval)\n",
    "print(bn.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2879, grad_fn=<SinBackward0>)\n",
      "tensor(16., grad_fn=<PowBackward0>)\n",
      "tensor(4., requires_grad=True)\n",
      "tensor(-7.6613)\n",
      "tensor(-0.9577)\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251841/420265378.py:17: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  print(z.grad)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "x = torch.tensor(4.0, requires_grad=True)\n",
    "y = x ** 2  # y = xÂ²\n",
    "y.retain_grad()\n",
    "z = torch.sin(y)\n",
    "\n",
    "print(z)\n",
    "print(y)\n",
    "print(x)\n",
    "\n",
    "z.backward()  # Compute gradients\n",
    "print(x.grad)  # Output: 4.0 (dy/dx = 2*x, at x=2)\n",
    "print(y.grad)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "# Define a function to be checkpointed\n",
    "def forward_func(input):\n",
    "    return torch.relu(input)\n",
    "#pdb.set_trace()\n",
    "\n",
    "# Input tensor\n",
    "input_tensor = torch.randn(5, requires_grad=True)\n",
    "\n",
    "# Use checkpoint\n",
    "output = checkpoint(forward_func, input_tensor)\n",
    "\n",
    "# Backward pass\n",
    "z=output.sum()\n",
    "z.backward()\n",
    "print(input_tensor.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "> \u001b[0;32m/tmp/ipykernel_446290/1839701227.py\u001b[0m(5)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{i} th loop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--Call--\n",
      "> \u001b[0;32m/home/mike_1102/miniconda3/envs/env02/lib/python3.11/site-packages/ipykernel/iostream.py\u001b[0m(655)\u001b[0;36mwrite\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    653 \u001b[0;31m                )\n",
      "\u001b[0m\u001b[0;32m    654 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 655 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type:ignore[override]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    656 \u001b[0;31m        \"\"\"Write to current stream after encoding if necessary\n",
      "\u001b[0m\u001b[0;32m    657 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/mike_1102/miniconda3/envs/env02/lib/python3.11/site-packages/ipykernel/iostream.py\u001b[0m(664)\u001b[0;36mwrite\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    662 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    663 \u001b[0;31m        \"\"\"\n",
      "\u001b[0m\u001b[0;32m--> 664 \u001b[0;31m        \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    665 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    666 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--Call--\n",
      "> \u001b[0;32m/home/mike_1102/miniconda3/envs/env02/lib/python3.11/site-packages/ipykernel/iostream.py\u001b[0m(505)\u001b[0;36mparent_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    503 \u001b[0;31m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    504 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 505 \u001b[0;31m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    506 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mparent_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    507 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/mike_1102/miniconda3/envs/env02/lib/python3.11/site-packages/ipykernel/iostream.py\u001b[0m(507)\u001b[0;36mparent_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    505 \u001b[0;31m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    506 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mparent_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 507 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    508 \u001b[0;31m            \u001b[0;31m# asyncio-specific\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    509 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "{i} th loop 0\n",
      "None\n",
      "> \u001b[0;32m/tmp/ipykernel_446290/1839701227.py\u001b[0m(5)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{i} th loop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "for i in range(10):\n",
    "\tpdb.set_trace()\n",
    "\tprint(\"{i} th loop\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdivide\u001b[39m(a, b):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#pdb.set_trace()  # Debugger starts here\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a \u001b[38;5;241m/\u001b[39m b\n\u001b[0;32m----> 7\u001b[0m divide(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mdivide\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdivide\u001b[39m(a, b):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#pdb.set_trace()  # Debugger starts here\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a \u001b[38;5;241m/\u001b[39m b\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "def divide(a, b):\n",
    "    #pdb.set_trace()  # Debugger starts here\n",
    "    return a / b\n",
    "\n",
    "divide(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_446290/2331031421.py\u001b[0m(5)\u001b[0;36mdivide\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0;31m#pdb.set_trace()  # Debugger starts here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "10\n",
      "10\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
